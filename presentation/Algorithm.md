(YOLOv8)

The Health Mirror system utilizes YOLOv8 from the YOLO family as its primary object detection engine. Four distinct pre-trained, weighted models have been developed specifically for health monitoring scenarios: DarkCircles.pt detects dark circles, Lip_types.pt monitors lip condition and chapped skin, skin.pt analyzes skin concerns, and health.pt integrates multiple clinically relevant features to create a comprehensive health indicator. This multi-model parallel architecture allows us to independently optimize different health status features, balancing precision and recall, and flexibly switch between or enable them simultaneously in real-world applications.

In neural network design, we selected YOLOv8 as the foundational detection framework and fine-tuned its architecture and optimized its lightweight architecture for health monitoring scenarios. YOLOv8 utilizes a modified CSPDarknet lightweight backbone network (Cross-Stage Partial Network). By splitting and merging features across stages, YOLOv8 effectively reduces redundant computation while preserving the full receptive field and gradient flow, ensuring high accuracy and efficiency on edge computing devices. This design is particularly well-suited for applications with limited hardware resources but requiring real-time computation, such as clinics, beauty salons, or home smart health monitoring mirrors.

For feature transfer, the neck architecture combines the Feature Pyramid Network (FPN) and Path Aggregation Network (PAN) to achieve bidirectional multi-scale feature fusion, ensuring accurate capture of features at different scales and levels, such as dark circles, skin condition, and lip changes.


To further improve operational efficiency and reduce model size, we introduced a post-training model compression strategy, including:

•	Pruning: Removing channels with low absolute weights to reduce computational effort and parameter count. Fine-tuning is then performed after pruning to maintain performance.
•	Distillation: Using a full-size YOLOv8 model as the teacher, its knowledge is transferred to a smaller, lightweight student model, effectively compensating for the accuracy loss caused by pruning.
Through this dual optimization strategy of lightweight backbone network and model compression, our system achieves high accuracy, low latency, and real-time processing capabilities on edge devices.
In terms of feature fusion design, the YOLOv8 neck structure integrates two multi-scale feature fusion strategies: the Feature Pyramid Network (FPN) and the Path Aggregation Network (PAN). FPN uses a top-down transfer method, transferring high-level semantic features to shallow layers, allowing lower-level features to acquire more semantic information. PAN, on the other hand, transfers detailed features from bottom to top, allowing deeper semantic layers to incorporate more boundary and texture information. This bidirectional feature fusion mechanism is particularly critical for face detection, as facial health-related features such as dark circles, skin condition, and lip condition are often distributed at different scales and levels of detail. High-precision detection requires a balance between global semantics and local texture.

In the detection head design, we adopted a hybrid prediction architecture that supports both anchor-based and anchor-free predictions. The anchor-based approach predicts the presence and location of objects for each predefined anchor box, achieving higher localization accuracy for small-scale objects such as the edges of dark circles and chapped lips. The anchor-free approach directly predicts the offset between the object center and the bounding box on the feature map, providing greater flexibility and generalization for objects with large scale variations or irregular positions, such as asymmetrical skin spots and chapped lips. To consider the advantages of both methods, we introduce a dynamic feature allocation strategy that can adaptively allocate the ratio of the two detection methods according to different scenarios, thereby improving the stability and recall rate of detection results.
For dataset processing, we used stratified splitting to divide the collected data into training, validation, and test sets to ensure consistency in class distribution across the different data subsets. When data volume is insufficient, we additionally implemented K-fold cross validation to evaluate the model's robustness under different data splits, mitigating overestimation or underestimation of performance due to data distribution bias.

For data augmentation, we combined multiple enhancement techniques to meet the needs of facial health detection:
•	Mosaic and MixUp: simulate different scene backgrounds and lighting conditions to improve the model's adaptability to environmental changes.
•	Random Affine and Perspective: generate images with different perspectives and geometric transformations to enhance the model's robustness to changes in angle and pose.
•	Resizing and HSV dithering: Simulate differences in resolution and white balance between different photographic devices, improving the model's tolerance to color and brightness variations.
•	Horizontal flipping and random cropping: Increase sample diversity and reduce the model's bias toward specific compositions or symmetrical structures.
During the training and evaluation phases, we introduced early stopping to prevent overfitting and ensure training stops at the optimal convergence point. Performance evaluation uses mAP at 0.70:0.95 as the core metric, supplemented by precision-recall curves, confusion matrices, and category-specific evaluation scores for multi-faceted performance analysis.

(OpenCV)

The Health Mirror system's image pre-processing module is based on OpenCV, featuring a flexible and high-performance workflow tailored to the needs of facial health monitoring. During the denoising and smoothing phase, OpenCV selects Gaussian, bilateral, or median filtering based on the scene and lighting conditions to reduce sensor noise and preserve edge details. In low-light environments, a non-local mean (NLM) algorithm is incorporated to further suppress noise. Exposure and contrast adjustments are then made using linear contrast stretching and gamma correction, and CLAHE (adaptive histogram equalization) is applied to the luminance channel in either the YCrCb or Lab color space to effectively enhance detail visibility in shadow areas.

For color correction, the Health Mirror system combines Gray World and Shades of Gray white balance estimation to reduce color casts caused by varying light sources and ensure consistent interpretation of skin and lip colors. For edge and morphological processing, Canny edge detection stabilizes image contours, while dilation, erosion, and opening and closing operations remove small areas of noise and correct region boundaries. The system supports multiple color space conversions (BGR, HSV, YCrCb, and Lab) and calculates ΔE and average a* values in HSV or Lab space for quantitative analysis of lip color and skin tone. Finally, using the facial detection frame and key point localization, we perform affine transformation and scale normalization to ensure input consistency for the subsequent YOLO detection and recognition stages.

We use different methods for feature analysis for different areas:
•	Dark circles: We capture the brightness and saturation distribution of the eye socket area and use the contrast difference with the surrounding skin to determine severity.

•	Lips: We calculate the average color and saturation in Lab or HSV color space, then use ΔE (color difference value) to compare with the skin color of the same person. This allows for more accurate analysis regardless of skin tone.

•	Skin detection: We not only analyze color uniformity but also use texture statistics (such as LBP and GLCM) for analysis. We then cross-validate with YOLO detection results to determine if any areas of the face appear sensitive or unhealthy.

To optimize performance, we employ techniques such as ROI cropping, SIMD/vectorization acceleration, and memory reuse to significantly reduce processing latency. In resource-constrained environments, the system dynamically adjusts input resolution and processing frequency to maintain smooth video while maintaining sufficient analysis accuracy.

(InsightFace)

During the facial recognition phase of Health Mirror system, we require a rigorous audit and quality control system. InsightFace detects facial landmarks such as the eyes, nose tip, and mouth corners. The system then performs a precise affine transformation to maintain consistent scale and pose in the input image, eliminating variations caused by different shooting angles and facial tilt. To ensure the stability and accuracy of subsequent recognition results, we perform quality checks on the input image. This includes using Laplace variance to measure blur, calculating visible facial area and occlusion ratio, and checking that the brightness range falls within an acceptable visual dynamic range. Low-quality samples are filtered out at this stage to avoid false matches due to image degradation.

During the facial recognition phase of our system, we prioritize rigorous quality control to ensure the stability and reliability of the final recognition results. First, InsightFace detects multiple key facial features, including the eyes, nose tip, and mouth corners. The system then performs a high-precision affine transformation to standardize the input image in terms of scale, position, and pose, effectively eliminating geometric variations caused by different shooting angles, facial tilt, and camera distance.

Next, we perform multi-level quality checks on the input image. For clarity, the system uses Laplacian variance to quantify image sharpness to determine blur or out-of-focus. For visibility, the system calculates the effective facial area and occlusion ratio to detect whether masks, hands, hair, or other objects obscure the presentation of key features. For brightness, the pixel value distribution is checked to ensure it falls within an acceptable visual dynamic range, avoiding overexposure or underexposure that could affect the stability of feature extraction. Images that fail to meet the standards for any of these metrics are automatically filtered at this stage to prevent low-quality samples from entering the subsequent process and causing false matches.
For feature embedding generation and model training, we convert each facial image into a 512-dimensional vector using L2 normalization. This ensures uniform scaling of features in the vector space, facilitating distance calculation and similarity comparison. During training, the system introduces an ArcFace-type angular margin loss function, with typical parameters set to a scaling factor s≈64 and an angular margin m≈0.5. This design effectively increases inter-class distances between different identities and reduces intra-class variation within the same identity, ensuring that features retain high discriminative power across a wide range of conditions.

This strategy maintains stable recognition performance under challenging scenarios such as changing lighting, age differences, and diverse expressions. It is suitable for long-term deployment in applications requiring extremely high accuracy and consistency, such as user authentication in health monitoring systems. It ensures that every login or recognition operation is completed within milliseconds, maintaining accurate and stable performance over time.

During the matching phase, the system uses cosine similarity as a metric to calculate the vector distance between the query sample and existing samples in the database and then determines whether they belong to the same identity based on a configurable threshold. To improve long-term accuracy, each user's database not only stores a single sample, but also maintains multiple templates covering facial features under different time, scenes, and appearance conditions.

The system dynamically updates and reweights existing templates using moving average or feature clustering methods to adapt to changes in a user's appearance over time, such as changes in hairstyle, wearing glasses, beard growth, and even skin color changes due to seasonality or lighting. This continuous optimization mechanism ensures that the system maintains high recognition stability over time without compromising recognition accuracy.

In terms of data management and privacy protection, the system has built-in localized feature storage and privacy isolation mechanisms to separate and store facial embeddings from personally identifiable information (PII). This ensures that the embedded features are stored locally, minimizing the risk of leakage and meeting strict data compliance requirements such as GDPR and local personal information regulations. 

To enhance security, we offer optional lightweight liveness detection capabilities, including blink analysis, head micro-motion detection, and prosthetic recognition based on facial texture and optical reflectance. These features effectively prevent photo attacks, screen replay attacks, and simple prosthetic spoofing without significantly increasing latency or reducing interactive smoothness. This balances ease of use and security, providing an additional line of defense for real-world deployments.
 

Deepsort (DeepSORT Tracking and Association)

During multi-target tracking, Health Mirror system uses the DeepSORT algorithm, tightly integrating motion models with appearance features to ensure cross-frame identity consistency and tracking stability. The core of the motion modeling is based on a Kalman filter, if targets exhibit near-constant velocity over short periods of time. Its state vector, which contains the center coordinates of the target's bounding box, aspect ratio, height, and the velocity component of these quantities, enables temporal extrapolation between detection results, maintaining smooth and stable trajectory estimation even in the presence of brief missed detections or jitter. This design maintains accurate positioning and identity continuity even in scenarios with moving targets, partial occlusion, or camera shake, minimizing target loss due to momentary detection interruptions.

During the target association process, Deepsort system first uses the Mahalanobis distance for preliminary screening, eliminating pairs that do not align with the current state uncertainty distribution to reduce the possibility of unsuitable matches. After screening, candidate pairs are assigned using the Hungarian algorithm to solve the minimum cost assignment problem. The cost function combines the bounding box Intersection over Union (IoU) and the cosine distance between appearance embeddings, forming a dual metric of motion and appearance. This design enables the system to maintain highly accurate identity association even when objects are partially occluded, overlap, or experience local changes in appearance, effectively reducing ID switching.

For tracking track management, the system implements a confirmation phase for newly detected objects. A minimum number of consecutive hits exceeding the min_hits threshold are required before the object is considered a valid track, preventing brief false detections that could consume system resources. Tracks that have not been successfully matched for an extended period are automatically deleted by the system after a mismatch period exceeding the max_age threshold, maintaining a concise and efficient tracking list. And at the same time, for targets that re-enter the scene, the system will restore their original IDs by combining appearance features and spatial proximity, minimizing the occurrence of identity resets, thereby improving the stability, continuity, and long-term trackability of the tracking results, and ensuring consistent and high-quality multi-target tracking results in complex dynamic environments.

The Health Mirror system's overall inference process begins with image input. It first pre-processes the image using OpenCV, which performs denoising, color correction, brightness and contrast adjustments, and affine transformation and rescaling to ensure image consistency in size and perspective. The image is then fed into the YOLOv8 detection module, which leverages a lightweight backbone network and a bidirectional feature fusion architecture to quickly and accurately identify health-related facial features such as dark circles, lip condition, and skin condition. To ensure real-time performance, YOLOv8 undergoes optimizations such as model pruning and knowledge distillation, ensuring smooth execution even on edge devices.

When the Health Mirror system requires identity verification, it activates the InsightFace facial recognition module to locate and align facial landmarks, generating an L2-normalized 512-dimensional feature vector. The ArcFace loss function and multi-sample template update mechanism ensure stable recognition results despite changes in appearance. Finally, the results are passed to the DeepSORT tracking module, which uses a Kalman filter to predict target positions and matches them using Mahalanobis distance and appearance similarity. The Hungarian algorithm then ensures ID consistency across frames, achieving stable and continuous multi-target tracking.
